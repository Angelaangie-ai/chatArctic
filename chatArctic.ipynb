{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import yaml"
      ],
      "metadata": {
        "id": "36qfbOUZM44c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tVJP8L4ix3cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/climate-change.yml', 'r') as file:\n",
        "     data = yaml.safe_load(file)\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "jovOn-wyNwPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785325e8-02f4-4017-e94d-42e3756399d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': ['climate change'],\n",
              " 'conversations': [['Why is the Arctic important in the climate change crisis?',\n",
              "   \"The Arctic is central to climate risks because it has a disproportionately strong effect on climate and weather in the rest of the world. The Arctic helps regulate the world's climate, influencing the Earth's atmospheric circulation systems.\",\n",
              "   'It has direct and indirect impacts on extreme heat and cold.',\n",
              "   'It warms at least three times faster than the rest of the planet.'],\n",
              "  ['What are the risks of the melting?',\n",
              "   'Extreme weather and sea level rise.',\n",
              "   'Supply chain disruption and heat stress.',\n",
              "   'Accelerates melting of the Greenland ice sheet - which contains the equivalent of 7.4m of sea level rise.'],\n",
              "  ['What is currently happening at the Arctic?',\n",
              "   'Arctic sea ice in winter, 2022, experienced the second earliest sea ice maximum due in part to heat waves in March.',\n",
              "   'This resulted in significant deterioration in sea ice concentrations to the east of Greenland.'],\n",
              "  ['What are some examples for extreme weather?',\n",
              "   'There were Arctic wildfires in Siberia.',\n",
              "   'In the spring 2022, there were a record number of tornadoes that pummelled in the United States.',\n",
              "   'Pakistan hit the warmest temperatures in 121 years.'],\n",
              "  ['How does the Arctic puts food security at risk?',\n",
              "   'It contributes to the risk of crop failures due to jet stream changes.',\n",
              "   'Extreme summer events disrupt the effective water management.'],\n",
              "  ['How does the Arctic influence the economic cost of climate change?',\n",
              "   'Recent extreme events like wildfires in Australia and the US have caused billions of USD worth of economic damage each.',\n",
              "   'Arctic warming alone is estimated for around 5% of all costs to climate change.',\n",
              "   'A small amount of these losses is occuring in the Arctic region itself, affecting indigenous communities who have adapted to live in harsh conditions.',\n",
              "   ['What are the pressures that Arctic communities are facing?'],\n",
              "   'Damages to infrastructure.',\n",
              "   'Growing wildfires.'],\n",
              "  ['How do we stay out of fossil fuels?',\n",
              "   'Government should ensure no new investments in fossil fuel development are made.',\n",
              "   'Banks should not finance oil, gas or ming projects in the Arctic.',\n",
              "   'We must keep banks like JPMorgan, Morgan Stanley, Goldman Sachs, Citi and Wells Fargo accountable to their pledges to not fund oil and gas.'],\n",
              "  ['How can we define a business roadmap for climate action?',\n",
              "   {'The roadmap will require coordinated action to push forward the emission mitigation options, highlighted by the IPCC': 'demand management, energy and materials efficiency, circular material flows, as well as abatement technologies and transformational changes in production processes.'},\n",
              "   'The carbon capture technology can help hard-to-abate sectors achieve net-zero, but should be used with caution.'],\n",
              "  ['How to reduce black carbon emissions?',\n",
              "   'Businesses who run or benefit from commercial shipping routes through the Arctic should immediately stop heavy fuel use.',\n",
              "   'Exemptions and allowances in its current proposals for a ban are estimated to reduce black carbon by just 5%, where a full ban on heavy fuel oil could reduce black carbon emissions by 30% in Arctic.'],\n",
              "  ['What are some solutions to help the Arctic?',\n",
              "   'No new investments in fossil fuels.',\n",
              "   'Phase out coal power.',\n",
              "   'Define a business roadmap for climate action.',\n",
              "   'Change shipping practices in the Arctic.',\n",
              "   'Improve food and water security.',\n",
              "   'Loss and damage payments.'],\n",
              "  ['How to align financial flows with net zero?',\n",
              "   'Businesses and governments should work towards putting a price on carbon, which allows companies to incorporate the externalities of their emissions accurately.',\n",
              "   'Businesses can begin by using an internal carbon price to support their transition plans.',\n",
              "   'Investors and financial institutions should invest in key technologies, especially in developing countries.'],\n",
              "  ['What are the adaptation, loss and damage practices?',\n",
              "   'Many developing countries already know that adaptation measures they need to put in place - put lack the finances to do so. This is critical for the countries that need to'],\n",
              "  ['What are some solutions to deal with extreme weather and sea-level rise?',\n",
              "   'One example of a solution for a nature-based infrastructure comprises of an artificial beach and dune landscape across 7 kilometres in Netherlands.',\n",
              "   'One example for a solution is The Coastal Forecasting Demonstration Project that provides an early warning system and alerts for coastal flooding in Pacific Island Countries.'],\n",
              "  ['How to improve food and water security?',\n",
              "   'Increase soil organic matter and erosion control, improve cropland, livestock, grazing land management.',\n",
              "   'Demand-side adaptation, such as adoption of healthy and sustainable diets, in conjunction with reduction in food loss and waste.'],\n",
              "  ['What is the concept of loss and damage payments?',\n",
              "   \"The world's richest nations should follow through on their climate finance promise, originally made in 2009, to pay US$100bn to developing countries.\",\n",
              "   'The UK House of Commons briefing highlights this target has been missed every year since 2013.'],\n",
              "  ['What are some regional solutions we can use to help the Arctic?',\n",
              "   'Build on indigenous intelligence and traditional knowledge.',\n",
              "   'More investment in the Arctic to help communities adapt to climate change.'],\n",
              "  ['Does oversleeping cause depression?',\n",
              "   \"It's important to remember that\\xa0oversleeping\\xa0is a possible symptom of\\xa0depression\\xa0and that\\xa0oversleeping\\xa0doesn't\\xa0cause depression. But it\\xa0can\\xa0exacerbate and worsen\\xa0depression symptoms\"],\n",
              "  ['How to utilize the knowledge of indigenous communities?',\n",
              "   'There are organizations such as Indigenous Guardians and Wildfire Management which utilize indigenous knowledge to build models for environmental management, fire stewardship, and increasing biodiversity on our planet.',\n",
              "   'One example of such a practice is utilizing the knowledge of The Inuit community in Canada to produce sea ice charts for the Sea Ice Climate Atlas.'],\n",
              "  ['How can we create more investment in the Arctic?',\n",
              "   'Investment from the private sector to support resilience.',\n",
              "   'Social enterprise serves as a model for resilience in the Arctic and globally.',\n",
              "   {'One such example of a social enterprise is': 'SmartICE. SmartICE partners with Arctic Indigenous communities to empower them to monitor the ice that not only acts as their harvesting platform and travel highway but is central to their culture and identity.'}],\n",
              "  ['How to support environmental management in the Arctic?',\n",
              "   'It is important to protect forests and peatland that can limit permafrost disruption.',\n",
              "   \"Areas with herds of large Arctic herbivores like reindeer, horses and bison have a soil temperature about 2 degrees colder compared to herd-free areas. Strategically resettling herds like these could help preserve the Arctic's permafrost.\"],\n",
              "  ['How to monitor the effects of climate change in the Arctic?',\n",
              "   'Monitoring changes in vegetation and permafrost thaw in the Arctic combined with distributed monitoring systems can highlight regions for preservation.',\n",
              "   'Emissions tracking can give rise to improved understanding of polluted transport into and out of the Arctic from extractive industries.'],\n",
              "  ['How is Arctic Basecamp helping the challenges in the Arctic?',\n",
              "   'Arctic Basecamp is a not-for-profit organization headquarted in the Netherlands. Our mission is to \"speak science to power\" and communicate how the Arctic is a critical barometer for, and a driver of, global risk. We support urgent low carbon action on insightful analysis that is supported by robust, rigorous and cutting-edge science.',\n",
              "   'By sharing knowledge and science, Arctic Basecamp works with partners to call for urgent action from global leaders to mitigate, adapt and build resilience to global risks from climate.']]}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convos = data['conversations']\n",
        "\n",
        "convos[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmTsPZSpOG0g",
        "outputId": "a85719a1-8617-4f90-d3fa-ea84daa35948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Why is the Arctic important in the climate change crisis?',\n",
              " \"The Arctic is central to climate risks because it has a disproportionately strong effect on climate and weather in the rest of the world. The Arctic helps regulate the world's climate, influencing the Earth's atmospheric circulation systems.\",\n",
              " 'It has direct and indirect impacts on extreme heat and cold.',\n",
              " 'It warms at least three times faster than the rest of the planet.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = []"
      ],
      "metadata": {
        "id": "o-v437pATBrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for convo in convos:\n",
        "  completion = ''\n",
        "  for i, dialog in enumerate(convo):\n",
        "    if i == 0:\n",
        "      prompt = dialog\n",
        "      # p_encode = prompt.encode(\"ascii\", \"ignore\")\n",
        "      # prompt = p_encode.decode()\n",
        "      prompt = prompt.replace(\"\\xa0\", \" \")\n",
        "      # print('prompt:',prompt)\n",
        "    else:\n",
        "      completion += \" \" + dialog\n",
        "      # c_encode = completion.encode(\"ascii\", \"ignore\")\n",
        "      # completion = c_encode.decode()\n",
        "      completion = completion.replace(\"\\xa0\", \" \")\n",
        "  completion = completion.strip()\n",
        "  line = {'prompt': prompt, 'completion': completion}\n",
        "  # print(line)\n",
        "  output.append(line)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "3Yz-LYKiOXln",
        "outputId": "7eb545ed-91d1-4d1a-a3c8-f48e3ff585f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c28491b822e4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;31m# print('prompt:',prompt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mcompletion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdialog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0;31m# c_encode = completion.encode(\"ascii\", \"ignore\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0;31m# completion = c_encode.decode()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "ijmYBGaTVqGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('climate-change.jsonl', 'w') as outfile:\n",
        "        for i in output:\n",
        "            json.dump(i, outfile)\n",
        "            outfile.write('\\n')\n",
        "\n",
        "\n",
        "files.download('climate-change.jsonl')\n"
      ],
      "metadata": {
        "id": "ETdV0OyYPFYZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c5a7f6b1-d74e-488e-eb69-819dd66bbd17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f4cf7e17-2e66-42f5-b684-71186698460a\", \"climate-change.jsonl\", 2936)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.25.0"
      ],
      "metadata": {
        "id": "2auTioYVSImG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "outputId": "5f0d1c3f-3783-425e-b713-d22d6913cbff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.25.0\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.25.0) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.25.0) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from openai==0.25.0) (1.5.3)\n",
            "Collecting pandas-stubs>=1.1.0.11 (from openai==0.25.0)\n",
            "  Downloading pandas_stubs-2.0.2.230605-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from openai==0.25.0) (3.0.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai==0.25.0) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from openai==0.25.0) (4.6.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>=3.0.7->openai==0.25.0) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.3->openai==0.25.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.3->openai==0.25.0) (2022.7.1)\n",
            "Collecting numpy (from openai==0.25.0)\n",
            "  Downloading numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-pytz>=2022.1.1 (from pandas-stubs>=1.1.0.11->openai==0.25.0)\n",
            "  Downloading types_pytz-2023.3.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.25.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.25.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.25.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.25.0) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.2.3->openai==0.25.0) (1.16.0)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55857 sha256=11c5764bb36ebfb600cf7e00439b56505a83c33321bd2fee382659915208fe98\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/5f/5e/43a5c7e951736aa9c66faafc0d493b2e3f7467cfbd399db109\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, numpy, pandas-stubs, openai\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.25.0 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.25.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.25.0 openai-0.25.0 pandas-stubs-2.0.2.230605 types-pytz-2023.3.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f '/content/climate-change-3.jsonl'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6I6uIECROn7",
        "outputId": "d2a40e56-4a70-4ccf-84ca-b6f72be21696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 10 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- There are 5 duplicated prompt-completion sets. These are rows: [5, 6, 7, 8, 9]\n",
            "- All prompts end with suffix `?`\n",
            "- All completions end with suffix `.`\n",
            "  WARNING: Some of your completions contain the suffix `.` more than once. We suggest that you review your completions and add a unique ending\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Remove 5 duplicate rows [Y/n]: n\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: y\n",
            "\n",
            "Wrote modified file to `/content/climate-change-3_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"/content/climate-change-3_prepared.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `?` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 2.58 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "3XfG69VTrEqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "gTVZLlf4lNHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = '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'"
      ],
      "metadata": {
        "id": "oV2vabvCXHxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!set OPENAI_API_KEY=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"
      ],
      "metadata": {
        "id": "FgO1egbbsXT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t \"/content/climate-change-3_prepared.jsonl\" -m ada --n_epochs 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epglrlaFTjtY",
        "outputId": "1d7d413f-1775-48a3-ea9e-e2ccc550b0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/2.92k [00:00<?, ?it/s]\rUpload progress: 100% 2.92k/2.92k [00:00<00:00, 3.20Mit/s]\n",
            "Uploaded file from /content/climate-change-3_prepared.jsonl: file-93he5ZC8v02SyxN5eSb3ytvS\n",
            "Created fine-tune: ft-8iOfmARWFw5yD4wpRBht4tsZ\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-07-02 20:26:57] Created fine-tune: ft-8iOfmARWFw5yD4wpRBht4tsZ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-pIIgVaNien0aXR6zEoxGfvrQ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQLBFgWGmhkb",
        "outputId": "4a83d9cb-c205-4876-efbb-177de896d504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-07-01 23:36:39] Created fine-tune: ft-pIIgVaNien0aXR6zEoxGfvrQ\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-pIIgVaNien0aXR6zEoxGfvrQ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-KkJq4fjwylBUfErjmmTQyAQG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6Bto94UnZN7",
        "outputId": "9ecd9c53-8d75-4ed6-9545-5afb517ebd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-07-01 22:35:42] Created fine-tune: ft-KkJq4fjwylBUfErjmmTQyAQG\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-KkJq4fjwylBUfErjmmTQyAQG\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-rqC2EgLBkJjAKtKXv8z9YOid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s_L3poYpdA9",
        "outputId": "c266478e-70e3-42bf-ac64-574f64f090e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-07-01 23:06:10] Created fine-tune: ft-rqC2EgLBkJjAKtKXv8z9YOid\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-rqC2EgLBkJjAKtKXv8z9YOid\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "query = 'hi i feel like ass'\n",
        "\n",
        "response = openai.Completion.create(\n",
        "                model=\"davinci:ft-personal-2022-08-20-13-32-16\",\n",
        "                prompt=\"The following is a conversation with a therapist and a user. The therapist is JOY, who uses compassionate listening to have helpful and meaningful conversations with users. JOY is empathic and friendly. JOY's objective is to make the user feel better by feeling heard. With each response, JOY offers follow-up questions to encourage openness and tries to continue the conversation in a natural way. \\n\\nJOY-> Hello, I am your personal mental health assistant. What's on your mind today?\\nUser->\"+query+\"JOY->\",\n",
        "                temperature=0.89,\n",
        "                max_tokens=162,\n",
        "                top_p=1,\n",
        "                frequency_penalty=0,\n",
        "                presence_penalty=0.6,\n",
        "                stop=[\"\\n\"]\n",
        "  )\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "NS1IRkd_Tlew",
        "outputId": "947896d0-1496-4a6a-9858-a8245004e3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidRequestError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-8d993c2669f3>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hi i feel like ass'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"davinci:ft-personal-2022-08-20-13-32-16\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"The following is a conversation with a therapist and a user. The therapist is JOY, who uses compassionate listening to have helpful and meaningful conversations with users. JOY is empathic and friendly. JOY's objective is to make the user feel better by feeling heard. With each response, JOY offers follow-up questions to encourage openness and tries to continue the conversation in a natural way. \\n\\nJOY-> Hello, I am your personal mental health assistant. What's on your mind today?\\nUser->\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"JOY->\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             )\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: The model: `davinci:ft-personal-2022-08-20-13-32-16` does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "odw3HUM2rmmw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}